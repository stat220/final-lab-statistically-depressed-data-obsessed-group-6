{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>timedelta</th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_tokens_content</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>n_non_stop_words</th>\n",
       "      <th>n_non_stop_unique_tokens</th>\n",
       "      <th>num_hrefs</th>\n",
       "      <th>num_self_hrefs</th>\n",
       "      <th>num_imgs</th>\n",
       "      <th>...</th>\n",
       "      <th>min_positive_polarity</th>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <th>min_negative_polarity</th>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "      <th>shares</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://mashable.com/2013/01/07/amazon-instant-...</td>\n",
       "      <td>731.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>0.663594</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.815385</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.70</td>\n",
       "      <td>-0.350000</td>\n",
       "      <td>-0.600</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.187500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://mashable.com/2013/01/07/ap-samsung-spon...</td>\n",
       "      <td>731.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>0.604743</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.791946</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.70</td>\n",
       "      <td>-0.118750</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://mashable.com/2013/01/07/apple-40-billio...</td>\n",
       "      <td>731.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>0.575130</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.663866</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.466667</td>\n",
       "      <td>-0.800</td>\n",
       "      <td>-0.133333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://mashable.com/2013/01/07/astronaut-notre...</td>\n",
       "      <td>731.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>531.0</td>\n",
       "      <td>0.503788</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.665635</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.80</td>\n",
       "      <td>-0.369697</td>\n",
       "      <td>-0.600</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://mashable.com/2013/01/07/att-u-verse-apps/</td>\n",
       "      <td>731.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1072.0</td>\n",
       "      <td>0.415646</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.540890</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.220192</td>\n",
       "      <td>-0.500</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39639</th>\n",
       "      <td>http://mashable.com/2014/12/27/samsung-app-aut...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>346.0</td>\n",
       "      <td>0.529052</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.684783</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.75</td>\n",
       "      <td>-0.260000</td>\n",
       "      <td>-0.500</td>\n",
       "      <td>-0.125000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39640</th>\n",
       "      <td>http://mashable.com/2014/12/27/seth-rogen-jame...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>328.0</td>\n",
       "      <td>0.696296</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.885057</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.70</td>\n",
       "      <td>-0.211111</td>\n",
       "      <td>-0.400</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39641</th>\n",
       "      <td>http://mashable.com/2014/12/27/son-pays-off-mo...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>442.0</td>\n",
       "      <td>0.516355</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.644128</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-0.356439</td>\n",
       "      <td>-0.800</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>1900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39642</th>\n",
       "      <td>http://mashable.com/2014/12/27/ukraine-blasts/</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>682.0</td>\n",
       "      <td>0.539493</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.692661</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-0.205246</td>\n",
       "      <td>-0.500</td>\n",
       "      <td>-0.012500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39643</th>\n",
       "      <td>http://mashable.com/2014/12/27/youtube-channel...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>0.701987</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>-0.200</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39644 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     url  timedelta  \\\n",
       "0      http://mashable.com/2013/01/07/amazon-instant-...      731.0   \n",
       "1      http://mashable.com/2013/01/07/ap-samsung-spon...      731.0   \n",
       "2      http://mashable.com/2013/01/07/apple-40-billio...      731.0   \n",
       "3      http://mashable.com/2013/01/07/astronaut-notre...      731.0   \n",
       "4       http://mashable.com/2013/01/07/att-u-verse-apps/      731.0   \n",
       "...                                                  ...        ...   \n",
       "39639  http://mashable.com/2014/12/27/samsung-app-aut...        8.0   \n",
       "39640  http://mashable.com/2014/12/27/seth-rogen-jame...        8.0   \n",
       "39641  http://mashable.com/2014/12/27/son-pays-off-mo...        8.0   \n",
       "39642     http://mashable.com/2014/12/27/ukraine-blasts/        8.0   \n",
       "39643  http://mashable.com/2014/12/27/youtube-channel...        8.0   \n",
       "\n",
       "       n_tokens_title  n_tokens_content  n_unique_tokens  n_non_stop_words  \\\n",
       "0                12.0             219.0         0.663594               1.0   \n",
       "1                 9.0             255.0         0.604743               1.0   \n",
       "2                 9.0             211.0         0.575130               1.0   \n",
       "3                 9.0             531.0         0.503788               1.0   \n",
       "4                13.0            1072.0         0.415646               1.0   \n",
       "...               ...               ...              ...               ...   \n",
       "39639            11.0             346.0         0.529052               1.0   \n",
       "39640            12.0             328.0         0.696296               1.0   \n",
       "39641            10.0             442.0         0.516355               1.0   \n",
       "39642             6.0             682.0         0.539493               1.0   \n",
       "39643            10.0             157.0         0.701987               1.0   \n",
       "\n",
       "       n_non_stop_unique_tokens  num_hrefs  num_self_hrefs  num_imgs  ...  \\\n",
       "0                      0.815385        4.0             2.0       1.0  ...   \n",
       "1                      0.791946        3.0             1.0       1.0  ...   \n",
       "2                      0.663866        3.0             1.0       1.0  ...   \n",
       "3                      0.665635        9.0             0.0       1.0  ...   \n",
       "4                      0.540890       19.0            19.0      20.0  ...   \n",
       "...                         ...        ...             ...       ...  ...   \n",
       "39639                  0.684783        9.0             7.0       1.0  ...   \n",
       "39640                  0.885057        9.0             7.0       3.0  ...   \n",
       "39641                  0.644128       24.0             1.0      12.0  ...   \n",
       "39642                  0.692661       10.0             1.0       1.0  ...   \n",
       "39643                  0.846154        1.0             1.0       0.0  ...   \n",
       "\n",
       "       min_positive_polarity  max_positive_polarity  avg_negative_polarity  \\\n",
       "0                   0.100000                   0.70              -0.350000   \n",
       "1                   0.033333                   0.70              -0.118750   \n",
       "2                   0.100000                   1.00              -0.466667   \n",
       "3                   0.136364                   0.80              -0.369697   \n",
       "4                   0.033333                   1.00              -0.220192   \n",
       "...                      ...                    ...                    ...   \n",
       "39639               0.100000                   0.75              -0.260000   \n",
       "39640               0.136364                   0.70              -0.211111   \n",
       "39641               0.136364                   0.50              -0.356439   \n",
       "39642               0.062500                   0.50              -0.205246   \n",
       "39643               0.100000                   0.50              -0.200000   \n",
       "\n",
       "       min_negative_polarity  max_negative_polarity  title_subjectivity  \\\n",
       "0                     -0.600              -0.200000            0.500000   \n",
       "1                     -0.125              -0.100000            0.000000   \n",
       "2                     -0.800              -0.133333            0.000000   \n",
       "3                     -0.600              -0.166667            0.000000   \n",
       "4                     -0.500              -0.050000            0.454545   \n",
       "...                      ...                    ...                 ...   \n",
       "39639                 -0.500              -0.125000            0.100000   \n",
       "39640                 -0.400              -0.100000            0.300000   \n",
       "39641                 -0.800              -0.166667            0.454545   \n",
       "39642                 -0.500              -0.012500            0.000000   \n",
       "39643                 -0.200              -0.200000            0.333333   \n",
       "\n",
       "       title_sentiment_polarity  abs_title_subjectivity  \\\n",
       "0                     -0.187500                0.000000   \n",
       "1                      0.000000                0.500000   \n",
       "2                      0.000000                0.500000   \n",
       "3                      0.000000                0.500000   \n",
       "4                      0.136364                0.045455   \n",
       "...                         ...                     ...   \n",
       "39639                  0.000000                0.400000   \n",
       "39640                  1.000000                0.200000   \n",
       "39641                  0.136364                0.045455   \n",
       "39642                  0.000000                0.500000   \n",
       "39643                  0.250000                0.166667   \n",
       "\n",
       "       abs_title_sentiment_polarity  shares  \n",
       "0                          0.187500     593  \n",
       "1                          0.000000     711  \n",
       "2                          0.000000    1500  \n",
       "3                          0.000000    1200  \n",
       "4                          0.136364     505  \n",
       "...                             ...     ...  \n",
       "39639                      0.000000    1800  \n",
       "39640                      1.000000    1900  \n",
       "39641                      0.136364    1900  \n",
       "39642                      0.000000    1100  \n",
       "39643                      0.250000    1300  \n",
       "\n",
       "[39644 rows x 61 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('https://richardson.byu.edu/220/OnlineNewsPopularity.csv', delimiter=',\\s+', engine='python')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count     39644.000000\n",
      "mean       3395.380184\n",
      "std       11626.950749\n",
      "min           1.000000\n",
      "25%         946.000000\n",
      "50%        1400.000000\n",
      "75%        2800.000000\n",
      "max      843300.000000\n",
      "Name: shares, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. Plot the target variable. Determine if the target variable seems appropriate or if any transformations are needed.\n",
    "shares = data.iloc[:, -1]\n",
    "\n",
    "print(shares.describe())\n",
    "\n",
    "plt.hist(shares, bins=30)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Apply a log transform because the variables shares are heavily skewed\n",
    "shares = np.log(shares)\n",
    "\n",
    "plt.hist(shares, bins=30)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>shares</td>      <th>  R-squared:         </th> <td>   0.127</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.126</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   101.0</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 05 Dec 2024</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>21:58:11</td>     <th>  Log-Likelihood:    </th> <td> -50705.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 39644</td>      <th>  AIC:               </th> <td>1.015e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 39586</td>      <th>  BIC:               </th> <td>1.020e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    57</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                <td></td>                   <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                         <td>  -23.8866</td> <td>  394.230</td> <td>   -0.061</td> <td> 0.952</td> <td> -796.587</td> <td>  748.814</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>timedelta</th>                     <td> 6.156e-05</td> <td> 2.97e-05</td> <td>    2.073</td> <td> 0.038</td> <td> 3.36e-06</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>n_tokens_title</th>                <td>    0.0081</td> <td>    0.002</td> <td>    3.689</td> <td> 0.000</td> <td>    0.004</td> <td>    0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>n_tokens_content</th>              <td>  4.06e-05</td> <td> 1.69e-05</td> <td>    2.401</td> <td> 0.016</td> <td> 7.45e-06</td> <td> 7.37e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>n_unique_tokens</th>               <td>    0.1626</td> <td>    0.146</td> <td>    1.117</td> <td> 0.264</td> <td>   -0.123</td> <td>    0.448</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>n_non_stop_words</th>              <td>    0.0769</td> <td>    0.447</td> <td>    0.172</td> <td> 0.863</td> <td>   -0.800</td> <td>    0.953</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>n_non_stop_unique_tokens</th>      <td>   -0.2426</td> <td>    0.123</td> <td>   -1.966</td> <td> 0.049</td> <td>   -0.484</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>num_hrefs</th>                     <td>    0.0042</td> <td>    0.001</td> <td>    8.290</td> <td> 0.000</td> <td>    0.003</td> <td>    0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>num_self_hrefs</th>                <td>   -0.0080</td> <td>    0.001</td> <td>   -5.916</td> <td> 0.000</td> <td>   -0.011</td> <td>   -0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>num_imgs</th>                      <td>    0.0024</td> <td>    0.001</td> <td>    3.583</td> <td> 0.000</td> <td>    0.001</td> <td>    0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>num_videos</th>                    <td>    0.0019</td> <td>    0.001</td> <td>    1.601</td> <td> 0.109</td> <td>   -0.000</td> <td>    0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>average_token_length</th>          <td>   -0.0919</td> <td>    0.018</td> <td>   -4.997</td> <td> 0.000</td> <td>   -0.128</td> <td>   -0.056</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>num_keywords</th>                  <td>    0.0119</td> <td>    0.003</td> <td>    4.250</td> <td> 0.000</td> <td>    0.006</td> <td>    0.017</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>data_channel_is_lifestyle</th>     <td>   -0.1025</td> <td>    0.030</td> <td>   -3.427</td> <td> 0.001</td> <td>   -0.161</td> <td>   -0.044</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>data_channel_is_entertainment</th> <td>   -0.1797</td> <td>    0.019</td> <td>   -9.265</td> <td> 0.000</td> <td>   -0.218</td> <td>   -0.142</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>data_channel_is_bus</th>           <td>   -0.1657</td> <td>    0.029</td> <td>   -5.721</td> <td> 0.000</td> <td>   -0.222</td> <td>   -0.109</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>data_channel_is_socmed</th>        <td>    0.1607</td> <td>    0.028</td> <td>    5.698</td> <td> 0.000</td> <td>    0.105</td> <td>    0.216</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>data_channel_is_tech</th>          <td>    0.1028</td> <td>    0.028</td> <td>    3.653</td> <td> 0.000</td> <td>    0.048</td> <td>    0.158</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>data_channel_is_world</th>         <td>   -0.0385</td> <td>    0.029</td> <td>   -1.345</td> <td> 0.179</td> <td>   -0.095</td> <td>    0.018</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>kw_min_min</th>                    <td>    0.0009</td> <td>    0.000</td> <td>    7.227</td> <td> 0.000</td> <td>    0.001</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>kw_max_min</th>                    <td> 1.706e-05</td> <td> 3.81e-06</td> <td>    4.477</td> <td> 0.000</td> <td> 9.59e-06</td> <td> 2.45e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>kw_avg_min</th>                    <td>   -0.0001</td> <td> 2.34e-05</td> <td>   -5.438</td> <td> 0.000</td> <td>   -0.000</td> <td>-8.15e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>kw_min_max</th>                    <td>-3.535e-07</td> <td> 8.91e-08</td> <td>   -3.968</td> <td> 0.000</td> <td>-5.28e-07</td> <td>-1.79e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>kw_max_max</th>                    <td> 5.049e-08</td> <td> 4.46e-08</td> <td>    1.131</td> <td> 0.258</td> <td> -3.7e-08</td> <td> 1.38e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>kw_avg_max</th>                    <td>-2.872e-07</td> <td> 6.42e-08</td> <td>   -4.475</td> <td> 0.000</td> <td>-4.13e-07</td> <td>-1.61e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>kw_min_avg</th>                    <td>-5.044e-05</td> <td> 5.72e-06</td> <td>   -8.812</td> <td> 0.000</td> <td>-6.17e-05</td> <td>-3.92e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>kw_max_avg</th>                    <td>-4.188e-05</td> <td> 1.91e-06</td> <td>  -21.872</td> <td> 0.000</td> <td>-4.56e-05</td> <td>-3.81e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>kw_avg_avg</th>                    <td>    0.0003</td> <td> 1.09e-05</td> <td>   30.768</td> <td> 0.000</td> <td>    0.000</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>self_reference_min_shares</th>     <td> 7.394e-07</td> <td> 5.69e-07</td> <td>    1.299</td> <td> 0.194</td> <td>-3.77e-07</td> <td> 1.86e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>self_reference_max_shares</th>     <td>-5.721e-10</td> <td> 3.09e-07</td> <td>   -0.002</td> <td> 0.999</td> <td>-6.06e-07</td> <td> 6.05e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>self_reference_avg_sharess</th>    <td> 1.441e-06</td> <td>  7.9e-07</td> <td>    1.824</td> <td> 0.068</td> <td>-1.08e-07</td> <td> 2.99e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>weekday_is_monday</th>             <td>   -4.2086</td> <td>   69.570</td> <td>   -0.060</td> <td> 0.952</td> <td> -140.568</td> <td>  132.150</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>weekday_is_tuesday</th>            <td>   -4.2762</td> <td>   69.570</td> <td>   -0.061</td> <td> 0.951</td> <td> -140.635</td> <td>  132.083</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>weekday_is_wednesday</th>          <td>   -4.2725</td> <td>   69.570</td> <td>   -0.061</td> <td> 0.951</td> <td> -140.631</td> <td>  132.086</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>weekday_is_thursday</th>           <td>   -4.2671</td> <td>   69.570</td> <td>   -0.061</td> <td> 0.951</td> <td> -140.626</td> <td>  132.092</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>weekday_is_friday</th>             <td>   -4.2035</td> <td>   69.570</td> <td>   -0.060</td> <td> 0.952</td> <td> -140.563</td> <td>  132.155</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>weekday_is_saturday</th>           <td>   -1.3276</td> <td>   23.190</td> <td>   -0.057</td> <td> 0.954</td> <td>  -46.781</td> <td>   44.125</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>weekday_is_sunday</th>             <td>   -1.3311</td> <td>   23.190</td> <td>   -0.057</td> <td> 0.954</td> <td>  -46.784</td> <td>   44.122</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_weekend</th>                    <td>   -2.6586</td> <td>   46.380</td> <td>   -0.057</td> <td> 0.954</td> <td>  -93.565</td> <td>   88.247</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>LDA_00</th>                        <td>   34.9294</td> <td>  463.799</td> <td>    0.075</td> <td> 0.940</td> <td> -874.128</td> <td>  943.987</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>LDA_01</th>                        <td>   34.5605</td> <td>  463.799</td> <td>    0.075</td> <td> 0.941</td> <td> -874.496</td> <td>  943.617</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>LDA_02</th>                        <td>   34.4726</td> <td>  463.799</td> <td>    0.074</td> <td> 0.941</td> <td> -874.585</td> <td>  943.530</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>LDA_03</th>                        <td>   34.5811</td> <td>  463.798</td> <td>    0.075</td> <td> 0.941</td> <td> -874.475</td> <td>  943.637</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>LDA_04</th>                        <td>   34.7076</td> <td>  463.799</td> <td>    0.075</td> <td> 0.940</td> <td> -874.349</td> <td>  943.764</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>global_subjectivity</th>           <td>    0.4078</td> <td>    0.064</td> <td>    6.338</td> <td> 0.000</td> <td>    0.282</td> <td>    0.534</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>global_sentiment_polarity</th>     <td>   -0.1122</td> <td>    0.126</td> <td>   -0.889</td> <td> 0.374</td> <td>   -0.360</td> <td>    0.135</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>global_rate_positive_words</th>    <td>   -1.1605</td> <td>    0.542</td> <td>   -2.140</td> <td> 0.032</td> <td>   -2.223</td> <td>   -0.098</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>global_rate_negative_words</th>    <td>    0.4878</td> <td>    1.035</td> <td>    0.471</td> <td> 0.638</td> <td>   -1.541</td> <td>    2.517</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rate_positive_words</th>           <td>    0.2768</td> <td>    0.437</td> <td>    0.633</td> <td> 0.527</td> <td>   -0.580</td> <td>    1.133</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rate_negative_words</th>           <td>    0.1238</td> <td>    0.440</td> <td>    0.281</td> <td> 0.779</td> <td>   -0.740</td> <td>    0.987</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>avg_positive_polarity</th>         <td>    0.0037</td> <td>    0.103</td> <td>    0.036</td> <td> 0.971</td> <td>   -0.199</td> <td>    0.206</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>min_positive_polarity</th>         <td>   -0.2726</td> <td>    0.087</td> <td>   -3.149</td> <td> 0.002</td> <td>   -0.442</td> <td>   -0.103</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>max_positive_polarity</th>         <td>   -0.0263</td> <td>    0.033</td> <td>   -0.806</td> <td> 0.420</td> <td>   -0.090</td> <td>    0.038</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>avg_negative_polarity</th>         <td>   -0.1479</td> <td>    0.095</td> <td>   -1.554</td> <td> 0.120</td> <td>   -0.335</td> <td>    0.039</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>min_negative_polarity</th>         <td>    0.0048</td> <td>    0.035</td> <td>    0.138</td> <td> 0.891</td> <td>   -0.063</td> <td>    0.073</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>max_negative_polarity</th>         <td>    0.0841</td> <td>    0.079</td> <td>    1.062</td> <td> 0.288</td> <td>   -0.071</td> <td>    0.239</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>title_subjectivity</th>            <td>    0.0590</td> <td>    0.021</td> <td>    2.845</td> <td> 0.004</td> <td>    0.018</td> <td>    0.100</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>title_sentiment_polarity</th>      <td>    0.0816</td> <td>    0.019</td> <td>    4.306</td> <td> 0.000</td> <td>    0.044</td> <td>    0.119</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>abs_title_subjectivity</th>        <td>    0.1419</td> <td>    0.028</td> <td>    5.151</td> <td> 0.000</td> <td>    0.088</td> <td>    0.196</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>abs_title_sentiment_polarity</th>  <td>    0.0265</td> <td>    0.030</td> <td>    0.886</td> <td> 0.375</td> <td>   -0.032</td> <td>    0.085</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>7288.957</td> <th>  Durbin-Watson:     </th> <td>   1.952</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>20307.680</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 0.985</td>  <th>  Prob(JB):          </th> <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td> 5.901</td>  <th>  Cond. No.          </th> <td>1.04e+16</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 2.51e-16. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}                   &      shares      & \\textbf{  R-squared:         } &     0.127   \\\\\n",
       "\\textbf{Model:}                           &       OLS        & \\textbf{  Adj. R-squared:    } &     0.126   \\\\\n",
       "\\textbf{Method:}                          &  Least Squares   & \\textbf{  F-statistic:       } &     101.0   \\\\\n",
       "\\textbf{Date:}                            & Thu, 05 Dec 2024 & \\textbf{  Prob (F-statistic):} &     0.00    \\\\\n",
       "\\textbf{Time:}                            &     21:58:11     & \\textbf{  Log-Likelihood:    } &   -50705.   \\\\\n",
       "\\textbf{No. Observations:}                &       39644      & \\textbf{  AIC:               } & 1.015e+05   \\\\\n",
       "\\textbf{Df Residuals:}                    &       39586      & \\textbf{  BIC:               } & 1.020e+05   \\\\\n",
       "\\textbf{Df Model:}                        &          57      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}                 &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                          & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const}                            &     -23.8866  &      394.230     &    -0.061  &         0.952        &     -796.587    &      748.814     \\\\\n",
       "\\textbf{timedelta}                        &    6.156e-05  &     2.97e-05     &     2.073  &         0.038        &     3.36e-06    &        0.000     \\\\\n",
       "\\textbf{n\\_tokens\\_title}                 &       0.0081  &        0.002     &     3.689  &         0.000        &        0.004    &        0.012     \\\\\n",
       "\\textbf{n\\_tokens\\_content}               &     4.06e-05  &     1.69e-05     &     2.401  &         0.016        &     7.45e-06    &     7.37e-05     \\\\\n",
       "\\textbf{n\\_unique\\_tokens}                &       0.1626  &        0.146     &     1.117  &         0.264        &       -0.123    &        0.448     \\\\\n",
       "\\textbf{n\\_non\\_stop\\_words}              &       0.0769  &        0.447     &     0.172  &         0.863        &       -0.800    &        0.953     \\\\\n",
       "\\textbf{n\\_non\\_stop\\_unique\\_tokens}     &      -0.2426  &        0.123     &    -1.966  &         0.049        &       -0.484    &       -0.001     \\\\\n",
       "\\textbf{num\\_hrefs}                       &       0.0042  &        0.001     &     8.290  &         0.000        &        0.003    &        0.005     \\\\\n",
       "\\textbf{num\\_self\\_hrefs}                 &      -0.0080  &        0.001     &    -5.916  &         0.000        &       -0.011    &       -0.005     \\\\\n",
       "\\textbf{num\\_imgs}                        &       0.0024  &        0.001     &     3.583  &         0.000        &        0.001    &        0.004     \\\\\n",
       "\\textbf{num\\_videos}                      &       0.0019  &        0.001     &     1.601  &         0.109        &       -0.000    &        0.004     \\\\\n",
       "\\textbf{average\\_token\\_length}           &      -0.0919  &        0.018     &    -4.997  &         0.000        &       -0.128    &       -0.056     \\\\\n",
       "\\textbf{num\\_keywords}                    &       0.0119  &        0.003     &     4.250  &         0.000        &        0.006    &        0.017     \\\\\n",
       "\\textbf{data\\_channel\\_is\\_lifestyle}     &      -0.1025  &        0.030     &    -3.427  &         0.001        &       -0.161    &       -0.044     \\\\\n",
       "\\textbf{data\\_channel\\_is\\_entertainment} &      -0.1797  &        0.019     &    -9.265  &         0.000        &       -0.218    &       -0.142     \\\\\n",
       "\\textbf{data\\_channel\\_is\\_bus}           &      -0.1657  &        0.029     &    -5.721  &         0.000        &       -0.222    &       -0.109     \\\\\n",
       "\\textbf{data\\_channel\\_is\\_socmed}        &       0.1607  &        0.028     &     5.698  &         0.000        &        0.105    &        0.216     \\\\\n",
       "\\textbf{data\\_channel\\_is\\_tech}          &       0.1028  &        0.028     &     3.653  &         0.000        &        0.048    &        0.158     \\\\\n",
       "\\textbf{data\\_channel\\_is\\_world}         &      -0.0385  &        0.029     &    -1.345  &         0.179        &       -0.095    &        0.018     \\\\\n",
       "\\textbf{kw\\_min\\_min}                     &       0.0009  &        0.000     &     7.227  &         0.000        &        0.001    &        0.001     \\\\\n",
       "\\textbf{kw\\_max\\_min}                     &    1.706e-05  &     3.81e-06     &     4.477  &         0.000        &     9.59e-06    &     2.45e-05     \\\\\n",
       "\\textbf{kw\\_avg\\_min}                     &      -0.0001  &     2.34e-05     &    -5.438  &         0.000        &       -0.000    &    -8.15e-05     \\\\\n",
       "\\textbf{kw\\_min\\_max}                     &   -3.535e-07  &     8.91e-08     &    -3.968  &         0.000        &    -5.28e-07    &    -1.79e-07     \\\\\n",
       "\\textbf{kw\\_max\\_max}                     &    5.049e-08  &     4.46e-08     &     1.131  &         0.258        &     -3.7e-08    &     1.38e-07     \\\\\n",
       "\\textbf{kw\\_avg\\_max}                     &   -2.872e-07  &     6.42e-08     &    -4.475  &         0.000        &    -4.13e-07    &    -1.61e-07     \\\\\n",
       "\\textbf{kw\\_min\\_avg}                     &   -5.044e-05  &     5.72e-06     &    -8.812  &         0.000        &    -6.17e-05    &    -3.92e-05     \\\\\n",
       "\\textbf{kw\\_max\\_avg}                     &   -4.188e-05  &     1.91e-06     &   -21.872  &         0.000        &    -4.56e-05    &    -3.81e-05     \\\\\n",
       "\\textbf{kw\\_avg\\_avg}                     &       0.0003  &     1.09e-05     &    30.768  &         0.000        &        0.000    &        0.000     \\\\\n",
       "\\textbf{self\\_reference\\_min\\_shares}     &    7.394e-07  &     5.69e-07     &     1.299  &         0.194        &    -3.77e-07    &     1.86e-06     \\\\\n",
       "\\textbf{self\\_reference\\_max\\_shares}     &   -5.721e-10  &     3.09e-07     &    -0.002  &         0.999        &    -6.06e-07    &     6.05e-07     \\\\\n",
       "\\textbf{self\\_reference\\_avg\\_sharess}    &    1.441e-06  &      7.9e-07     &     1.824  &         0.068        &    -1.08e-07    &     2.99e-06     \\\\\n",
       "\\textbf{weekday\\_is\\_monday}              &      -4.2086  &       69.570     &    -0.060  &         0.952        &     -140.568    &      132.150     \\\\\n",
       "\\textbf{weekday\\_is\\_tuesday}             &      -4.2762  &       69.570     &    -0.061  &         0.951        &     -140.635    &      132.083     \\\\\n",
       "\\textbf{weekday\\_is\\_wednesday}           &      -4.2725  &       69.570     &    -0.061  &         0.951        &     -140.631    &      132.086     \\\\\n",
       "\\textbf{weekday\\_is\\_thursday}            &      -4.2671  &       69.570     &    -0.061  &         0.951        &     -140.626    &      132.092     \\\\\n",
       "\\textbf{weekday\\_is\\_friday}              &      -4.2035  &       69.570     &    -0.060  &         0.952        &     -140.563    &      132.155     \\\\\n",
       "\\textbf{weekday\\_is\\_saturday}            &      -1.3276  &       23.190     &    -0.057  &         0.954        &      -46.781    &       44.125     \\\\\n",
       "\\textbf{weekday\\_is\\_sunday}              &      -1.3311  &       23.190     &    -0.057  &         0.954        &      -46.784    &       44.122     \\\\\n",
       "\\textbf{is\\_weekend}                      &      -2.6586  &       46.380     &    -0.057  &         0.954        &      -93.565    &       88.247     \\\\\n",
       "\\textbf{LDA\\_00}                          &      34.9294  &      463.799     &     0.075  &         0.940        &     -874.128    &      943.987     \\\\\n",
       "\\textbf{LDA\\_01}                          &      34.5605  &      463.799     &     0.075  &         0.941        &     -874.496    &      943.617     \\\\\n",
       "\\textbf{LDA\\_02}                          &      34.4726  &      463.799     &     0.074  &         0.941        &     -874.585    &      943.530     \\\\\n",
       "\\textbf{LDA\\_03}                          &      34.5811  &      463.798     &     0.075  &         0.941        &     -874.475    &      943.637     \\\\\n",
       "\\textbf{LDA\\_04}                          &      34.7076  &      463.799     &     0.075  &         0.940        &     -874.349    &      943.764     \\\\\n",
       "\\textbf{global\\_subjectivity}             &       0.4078  &        0.064     &     6.338  &         0.000        &        0.282    &        0.534     \\\\\n",
       "\\textbf{global\\_sentiment\\_polarity}      &      -0.1122  &        0.126     &    -0.889  &         0.374        &       -0.360    &        0.135     \\\\\n",
       "\\textbf{global\\_rate\\_positive\\_words}    &      -1.1605  &        0.542     &    -2.140  &         0.032        &       -2.223    &       -0.098     \\\\\n",
       "\\textbf{global\\_rate\\_negative\\_words}    &       0.4878  &        1.035     &     0.471  &         0.638        &       -1.541    &        2.517     \\\\\n",
       "\\textbf{rate\\_positive\\_words}            &       0.2768  &        0.437     &     0.633  &         0.527        &       -0.580    &        1.133     \\\\\n",
       "\\textbf{rate\\_negative\\_words}            &       0.1238  &        0.440     &     0.281  &         0.779        &       -0.740    &        0.987     \\\\\n",
       "\\textbf{avg\\_positive\\_polarity}          &       0.0037  &        0.103     &     0.036  &         0.971        &       -0.199    &        0.206     \\\\\n",
       "\\textbf{min\\_positive\\_polarity}          &      -0.2726  &        0.087     &    -3.149  &         0.002        &       -0.442    &       -0.103     \\\\\n",
       "\\textbf{max\\_positive\\_polarity}          &      -0.0263  &        0.033     &    -0.806  &         0.420        &       -0.090    &        0.038     \\\\\n",
       "\\textbf{avg\\_negative\\_polarity}          &      -0.1479  &        0.095     &    -1.554  &         0.120        &       -0.335    &        0.039     \\\\\n",
       "\\textbf{min\\_negative\\_polarity}          &       0.0048  &        0.035     &     0.138  &         0.891        &       -0.063    &        0.073     \\\\\n",
       "\\textbf{max\\_negative\\_polarity}          &       0.0841  &        0.079     &     1.062  &         0.288        &       -0.071    &        0.239     \\\\\n",
       "\\textbf{title\\_subjectivity}              &       0.0590  &        0.021     &     2.845  &         0.004        &        0.018    &        0.100     \\\\\n",
       "\\textbf{title\\_sentiment\\_polarity}       &       0.0816  &        0.019     &     4.306  &         0.000        &        0.044    &        0.119     \\\\\n",
       "\\textbf{abs\\_title\\_subjectivity}         &       0.1419  &        0.028     &     5.151  &         0.000        &        0.088    &        0.196     \\\\\n",
       "\\textbf{abs\\_title\\_sentiment\\_polarity}  &       0.0265  &        0.030     &     0.886  &         0.375        &       -0.032    &        0.085     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 7288.957 & \\textbf{  Durbin-Watson:     } &     1.952  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000  & \\textbf{  Jarque-Bera (JB):  } & 20307.680  \\\\\n",
       "\\textbf{Skew:}          &   0.985  & \\textbf{  Prob(JB):          } &      0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &   5.901  & \\textbf{  Cond. No.          } &  1.04e+16  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The smallest eigenvalue is 2.51e-16. This might indicate that there are \\newline\n",
       " strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                 shares   R-squared:                       0.127\n",
       "Model:                            OLS   Adj. R-squared:                  0.126\n",
       "Method:                 Least Squares   F-statistic:                     101.0\n",
       "Date:                Thu, 05 Dec 2024   Prob (F-statistic):               0.00\n",
       "Time:                        21:58:11   Log-Likelihood:                -50705.\n",
       "No. Observations:               39644   AIC:                         1.015e+05\n",
       "Df Residuals:                   39586   BIC:                         1.020e+05\n",
       "Df Model:                          57                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=================================================================================================\n",
       "                                    coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------------------------\n",
       "const                           -23.8866    394.230     -0.061      0.952    -796.587     748.814\n",
       "timedelta                      6.156e-05   2.97e-05      2.073      0.038    3.36e-06       0.000\n",
       "n_tokens_title                    0.0081      0.002      3.689      0.000       0.004       0.012\n",
       "n_tokens_content                4.06e-05   1.69e-05      2.401      0.016    7.45e-06    7.37e-05\n",
       "n_unique_tokens                   0.1626      0.146      1.117      0.264      -0.123       0.448\n",
       "n_non_stop_words                  0.0769      0.447      0.172      0.863      -0.800       0.953\n",
       "n_non_stop_unique_tokens         -0.2426      0.123     -1.966      0.049      -0.484      -0.001\n",
       "num_hrefs                         0.0042      0.001      8.290      0.000       0.003       0.005\n",
       "num_self_hrefs                   -0.0080      0.001     -5.916      0.000      -0.011      -0.005\n",
       "num_imgs                          0.0024      0.001      3.583      0.000       0.001       0.004\n",
       "num_videos                        0.0019      0.001      1.601      0.109      -0.000       0.004\n",
       "average_token_length             -0.0919      0.018     -4.997      0.000      -0.128      -0.056\n",
       "num_keywords                      0.0119      0.003      4.250      0.000       0.006       0.017\n",
       "data_channel_is_lifestyle        -0.1025      0.030     -3.427      0.001      -0.161      -0.044\n",
       "data_channel_is_entertainment    -0.1797      0.019     -9.265      0.000      -0.218      -0.142\n",
       "data_channel_is_bus              -0.1657      0.029     -5.721      0.000      -0.222      -0.109\n",
       "data_channel_is_socmed            0.1607      0.028      5.698      0.000       0.105       0.216\n",
       "data_channel_is_tech              0.1028      0.028      3.653      0.000       0.048       0.158\n",
       "data_channel_is_world            -0.0385      0.029     -1.345      0.179      -0.095       0.018\n",
       "kw_min_min                        0.0009      0.000      7.227      0.000       0.001       0.001\n",
       "kw_max_min                     1.706e-05   3.81e-06      4.477      0.000    9.59e-06    2.45e-05\n",
       "kw_avg_min                       -0.0001   2.34e-05     -5.438      0.000      -0.000   -8.15e-05\n",
       "kw_min_max                    -3.535e-07   8.91e-08     -3.968      0.000   -5.28e-07   -1.79e-07\n",
       "kw_max_max                     5.049e-08   4.46e-08      1.131      0.258    -3.7e-08    1.38e-07\n",
       "kw_avg_max                    -2.872e-07   6.42e-08     -4.475      0.000   -4.13e-07   -1.61e-07\n",
       "kw_min_avg                    -5.044e-05   5.72e-06     -8.812      0.000   -6.17e-05   -3.92e-05\n",
       "kw_max_avg                    -4.188e-05   1.91e-06    -21.872      0.000   -4.56e-05   -3.81e-05\n",
       "kw_avg_avg                        0.0003   1.09e-05     30.768      0.000       0.000       0.000\n",
       "self_reference_min_shares      7.394e-07   5.69e-07      1.299      0.194   -3.77e-07    1.86e-06\n",
       "self_reference_max_shares     -5.721e-10   3.09e-07     -0.002      0.999   -6.06e-07    6.05e-07\n",
       "self_reference_avg_sharess     1.441e-06    7.9e-07      1.824      0.068   -1.08e-07    2.99e-06\n",
       "weekday_is_monday                -4.2086     69.570     -0.060      0.952    -140.568     132.150\n",
       "weekday_is_tuesday               -4.2762     69.570     -0.061      0.951    -140.635     132.083\n",
       "weekday_is_wednesday             -4.2725     69.570     -0.061      0.951    -140.631     132.086\n",
       "weekday_is_thursday              -4.2671     69.570     -0.061      0.951    -140.626     132.092\n",
       "weekday_is_friday                -4.2035     69.570     -0.060      0.952    -140.563     132.155\n",
       "weekday_is_saturday              -1.3276     23.190     -0.057      0.954     -46.781      44.125\n",
       "weekday_is_sunday                -1.3311     23.190     -0.057      0.954     -46.784      44.122\n",
       "is_weekend                       -2.6586     46.380     -0.057      0.954     -93.565      88.247\n",
       "LDA_00                           34.9294    463.799      0.075      0.940    -874.128     943.987\n",
       "LDA_01                           34.5605    463.799      0.075      0.941    -874.496     943.617\n",
       "LDA_02                           34.4726    463.799      0.074      0.941    -874.585     943.530\n",
       "LDA_03                           34.5811    463.798      0.075      0.941    -874.475     943.637\n",
       "LDA_04                           34.7076    463.799      0.075      0.940    -874.349     943.764\n",
       "global_subjectivity               0.4078      0.064      6.338      0.000       0.282       0.534\n",
       "global_sentiment_polarity        -0.1122      0.126     -0.889      0.374      -0.360       0.135\n",
       "global_rate_positive_words       -1.1605      0.542     -2.140      0.032      -2.223      -0.098\n",
       "global_rate_negative_words        0.4878      1.035      0.471      0.638      -1.541       2.517\n",
       "rate_positive_words               0.2768      0.437      0.633      0.527      -0.580       1.133\n",
       "rate_negative_words               0.1238      0.440      0.281      0.779      -0.740       0.987\n",
       "avg_positive_polarity             0.0037      0.103      0.036      0.971      -0.199       0.206\n",
       "min_positive_polarity            -0.2726      0.087     -3.149      0.002      -0.442      -0.103\n",
       "max_positive_polarity            -0.0263      0.033     -0.806      0.420      -0.090       0.038\n",
       "avg_negative_polarity            -0.1479      0.095     -1.554      0.120      -0.335       0.039\n",
       "min_negative_polarity             0.0048      0.035      0.138      0.891      -0.063       0.073\n",
       "max_negative_polarity             0.0841      0.079      1.062      0.288      -0.071       0.239\n",
       "title_subjectivity                0.0590      0.021      2.845      0.004       0.018       0.100\n",
       "title_sentiment_polarity          0.0816      0.019      4.306      0.000       0.044       0.119\n",
       "abs_title_subjectivity            0.1419      0.028      5.151      0.000       0.088       0.196\n",
       "abs_title_sentiment_polarity      0.0265      0.030      0.886      0.375      -0.032       0.085\n",
       "==============================================================================\n",
       "Omnibus:                     7288.957   Durbin-Watson:                   1.952\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            20307.680\n",
       "Skew:                           0.985   Prob(JB):                         0.00\n",
       "Kurtosis:                       5.901   Cond. No.                     1.04e+16\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 2.51e-16. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Build a linear regression model without higher-order terms and identify the most significant predictors.\n",
    "def remove_worst_feature(model, X):\n",
    "    worst_feature = model.pvalues.drop(\"const\").idxmax()\n",
    "    print(f\"Removing {worst_feature} with p-value {model.pvalues.max()}\")\n",
    "    X = X.drop(worst_feature, axis=1)\n",
    "    return X\n",
    "\n",
    "def remove_insignificant_features(model, X, y):\n",
    "    while model.pvalues.max() > 0.05:\n",
    "        X = remove_worst_feature(model, X)\n",
    "        model = sm.OLS(y, X).fit()\n",
    "    return model, X\n",
    "\n",
    "X = data.drop([\"shares\", \"url\"], axis=1).astype(float)\n",
    "X = sm.add_constant(X)\n",
    "y = np.log(data[\"shares\"]).astype(float)\n",
    "\n",
    "linear_model = sm.OLS(y, X).fit()\n",
    "linear_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing self_reference_max_shares with p-value 0.9985225129173783\n",
      "Removing avg_positive_polarity with p-value 0.9711130490554427\n",
      "Removing weekday_is_saturday with p-value 0.9546266486279503\n",
      "Removing is_weekend with p-value 0.954583839408575\n",
      "Removing LDA_02 with p-value 0.9523481420933932\n",
      "Removing min_negative_polarity with p-value 0.88939371480128\n",
      "Removing weekday_is_sunday with p-value 0.8860736278559794\n",
      "Removing global_rate_negative_words with p-value 0.6270525305499155\n",
      "Removing max_positive_polarity with p-value 0.3997371499616633\n",
      "Removing n_non_stop_words with p-value 0.44618402168361715\n",
      "Removing abs_title_sentiment_polarity with p-value 0.37811851191539325\n",
      "Removing kw_max_max with p-value 0.2592122979978594\n",
      "Removing data_channel_is_world with p-value 0.22100542541512572\n",
      "Removing max_negative_polarity with p-value 0.21880833497859853\n",
      "Removing num_videos with p-value 0.10673030213012387\n",
      "Removing global_sentiment_polarity with p-value 0.07046144419701945\n",
      "Removing self_reference_min_shares with p-value 0.06400657151191137\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>shares</td>      <th>  R-squared:         </th> <td>   0.127</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.126</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   136.7</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 05 Dec 2024</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>21:58:13</td>     <th>  Log-Likelihood:    </th> <td> -50713.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 39644</td>      <th>  AIC:               </th> <td>1.015e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 39601</td>      <th>  BIC:               </th> <td>1.019e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    42</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                <td></td>                   <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                         <td>    6.5863</td> <td>    0.054</td> <td>  122.400</td> <td> 0.000</td> <td>    6.481</td> <td>    6.692</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>timedelta</th>                     <td> 5.821e-05</td> <td> 2.87e-05</td> <td>    2.031</td> <td> 0.042</td> <td> 2.04e-06</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>n_tokens_title</th>                <td>    0.0081</td> <td>    0.002</td> <td>    3.657</td> <td> 0.000</td> <td>    0.004</td> <td>    0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>n_tokens_content</th>              <td> 5.194e-05</td> <td> 1.26e-05</td> <td>    4.132</td> <td> 0.000</td> <td> 2.73e-05</td> <td> 7.66e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>n_unique_tokens</th>               <td>    0.2624</td> <td>    0.109</td> <td>    2.399</td> <td> 0.016</td> <td>    0.048</td> <td>    0.477</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>n_non_stop_unique_tokens</th>      <td>   -0.2799</td> <td>    0.118</td> <td>   -2.374</td> <td> 0.018</td> <td>   -0.511</td> <td>   -0.049</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>num_hrefs</th>                     <td>    0.0042</td> <td>    0.001</td> <td>    8.441</td> <td> 0.000</td> <td>    0.003</td> <td>    0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>num_self_hrefs</th>                <td>   -0.0080</td> <td>    0.001</td> <td>   -6.104</td> <td> 0.000</td> <td>   -0.011</td> <td>   -0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>num_imgs</th>                      <td>    0.0023</td> <td>    0.001</td> <td>    3.474</td> <td> 0.001</td> <td>    0.001</td> <td>    0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>average_token_length</th>          <td>   -0.0955</td> <td>    0.018</td> <td>   -5.341</td> <td> 0.000</td> <td>   -0.131</td> <td>   -0.060</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>num_keywords</th>                  <td>    0.0124</td> <td>    0.003</td> <td>    4.458</td> <td> 0.000</td> <td>    0.007</td> <td>    0.018</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>data_channel_is_lifestyle</th>     <td>   -0.0830</td> <td>    0.025</td> <td>   -3.270</td> <td> 0.001</td> <td>   -0.133</td> <td>   -0.033</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>data_channel_is_entertainment</th> <td>   -0.1647</td> <td>    0.017</td> <td>   -9.646</td> <td> 0.000</td> <td>   -0.198</td> <td>   -0.131</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>data_channel_is_bus</th>           <td>   -0.1463</td> <td>    0.024</td> <td>   -6.080</td> <td> 0.000</td> <td>   -0.193</td> <td>   -0.099</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>data_channel_is_socmed</th>        <td>    0.1828</td> <td>    0.023</td> <td>    7.887</td> <td> 0.000</td> <td>    0.137</td> <td>    0.228</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>data_channel_is_tech</th>          <td>    0.1262</td> <td>    0.022</td> <td>    5.863</td> <td> 0.000</td> <td>    0.084</td> <td>    0.168</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>kw_min_min</th>                    <td>    0.0008</td> <td> 8.64e-05</td> <td>    9.334</td> <td> 0.000</td> <td>    0.001</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>kw_max_min</th>                    <td> 1.742e-05</td> <td> 3.81e-06</td> <td>    4.578</td> <td> 0.000</td> <td> 9.96e-06</td> <td> 2.49e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>kw_avg_min</th>                    <td>   -0.0001</td> <td> 2.34e-05</td> <td>   -5.498</td> <td> 0.000</td> <td>   -0.000</td> <td>-8.28e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>kw_min_max</th>                    <td>-3.716e-07</td> <td> 8.83e-08</td> <td>   -4.210</td> <td> 0.000</td> <td>-5.45e-07</td> <td>-1.99e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>kw_avg_max</th>                    <td>-2.527e-07</td> <td> 6.05e-08</td> <td>   -4.177</td> <td> 0.000</td> <td>-3.71e-07</td> <td>-1.34e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>kw_min_avg</th>                    <td>-5.138e-05</td> <td>  5.7e-06</td> <td>   -9.017</td> <td> 0.000</td> <td>-6.25e-05</td> <td>-4.02e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>kw_max_avg</th>                    <td>-4.254e-05</td> <td> 1.89e-06</td> <td>  -22.512</td> <td> 0.000</td> <td>-4.62e-05</td> <td>-3.88e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>kw_avg_avg</th>                    <td>    0.0003</td> <td> 1.07e-05</td> <td>   31.601</td> <td> 0.000</td> <td>    0.000</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>self_reference_avg_sharess</th>    <td> 1.946e-06</td> <td> 1.85e-07</td> <td>   10.525</td> <td> 0.000</td> <td> 1.58e-06</td> <td> 2.31e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>weekday_is_monday</th>             <td>   -0.2205</td> <td>    0.016</td> <td>  -13.573</td> <td> 0.000</td> <td>   -0.252</td> <td>   -0.189</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>weekday_is_tuesday</th>            <td>   -0.2875</td> <td>    0.016</td> <td>  -18.108</td> <td> 0.000</td> <td>   -0.319</td> <td>   -0.256</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>weekday_is_wednesday</th>          <td>   -0.2843</td> <td>    0.016</td> <td>  -17.902</td> <td> 0.000</td> <td>   -0.315</td> <td>   -0.253</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>weekday_is_thursday</th>           <td>   -0.2789</td> <td>    0.016</td> <td>  -17.503</td> <td> 0.000</td> <td>   -0.310</td> <td>   -0.248</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>weekday_is_friday</th>             <td>   -0.2152</td> <td>    0.017</td> <td>  -12.815</td> <td> 0.000</td> <td>   -0.248</td> <td>   -0.182</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>LDA_00</th>                        <td>    0.4729</td> <td>    0.036</td> <td>   13.254</td> <td> 0.000</td> <td>    0.403</td> <td>    0.543</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>LDA_01</th>                        <td>    0.1157</td> <td>    0.032</td> <td>    3.636</td> <td> 0.000</td> <td>    0.053</td> <td>    0.178</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>LDA_03</th>                        <td>    0.1409</td> <td>    0.028</td> <td>    5.116</td> <td> 0.000</td> <td>    0.087</td> <td>    0.195</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>LDA_04</th>                        <td>    0.2510</td> <td>    0.033</td> <td>    7.641</td> <td> 0.000</td> <td>    0.187</td> <td>    0.315</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>global_subjectivity</th>           <td>    0.3955</td> <td>    0.060</td> <td>    6.573</td> <td> 0.000</td> <td>    0.278</td> <td>    0.513</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>global_rate_positive_words</th>    <td>   -1.1234</td> <td>    0.365</td> <td>   -3.080</td> <td> 0.002</td> <td>   -1.838</td> <td>   -0.409</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rate_positive_words</th>           <td>    0.2874</td> <td>    0.103</td> <td>    2.784</td> <td> 0.005</td> <td>    0.085</td> <td>    0.490</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rate_negative_words</th>           <td>    0.2376</td> <td>    0.104</td> <td>    2.292</td> <td> 0.022</td> <td>    0.034</td> <td>    0.441</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>min_positive_polarity</th>         <td>   -0.3141</td> <td>    0.072</td> <td>   -4.379</td> <td> 0.000</td> <td>   -0.455</td> <td>   -0.173</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>avg_negative_polarity</th>         <td>   -0.1176</td> <td>    0.041</td> <td>   -2.833</td> <td> 0.005</td> <td>   -0.199</td> <td>   -0.036</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>title_subjectivity</th>            <td>    0.0712</td> <td>    0.016</td> <td>    4.441</td> <td> 0.000</td> <td>    0.040</td> <td>    0.103</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>title_sentiment_polarity</th>      <td>    0.0838</td> <td>    0.018</td> <td>    4.770</td> <td> 0.000</td> <td>    0.049</td> <td>    0.118</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>abs_title_subjectivity</th>        <td>    0.1384</td> <td>    0.027</td> <td>    5.043</td> <td> 0.000</td> <td>    0.085</td> <td>    0.192</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>7285.525</td> <th>  Durbin-Watson:     </th> <td>   1.952</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>20289.897</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 0.984</td>  <th>  Prob(JB):          </th> <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td> 5.900</td>  <th>  Cond. No.          </th> <td>2.46e+07</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 2.46e+07. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}                   &      shares      & \\textbf{  R-squared:         } &     0.127   \\\\\n",
       "\\textbf{Model:}                           &       OLS        & \\textbf{  Adj. R-squared:    } &     0.126   \\\\\n",
       "\\textbf{Method:}                          &  Least Squares   & \\textbf{  F-statistic:       } &     136.7   \\\\\n",
       "\\textbf{Date:}                            & Thu, 05 Dec 2024 & \\textbf{  Prob (F-statistic):} &     0.00    \\\\\n",
       "\\textbf{Time:}                            &     21:58:13     & \\textbf{  Log-Likelihood:    } &   -50713.   \\\\\n",
       "\\textbf{No. Observations:}                &       39644      & \\textbf{  AIC:               } & 1.015e+05   \\\\\n",
       "\\textbf{Df Residuals:}                    &       39601      & \\textbf{  BIC:               } & 1.019e+05   \\\\\n",
       "\\textbf{Df Model:}                        &          42      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}                 &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                          & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const}                            &       6.5863  &        0.054     &   122.400  &         0.000        &        6.481    &        6.692     \\\\\n",
       "\\textbf{timedelta}                        &    5.821e-05  &     2.87e-05     &     2.031  &         0.042        &     2.04e-06    &        0.000     \\\\\n",
       "\\textbf{n\\_tokens\\_title}                 &       0.0081  &        0.002     &     3.657  &         0.000        &        0.004    &        0.012     \\\\\n",
       "\\textbf{n\\_tokens\\_content}               &    5.194e-05  &     1.26e-05     &     4.132  &         0.000        &     2.73e-05    &     7.66e-05     \\\\\n",
       "\\textbf{n\\_unique\\_tokens}                &       0.2624  &        0.109     &     2.399  &         0.016        &        0.048    &        0.477     \\\\\n",
       "\\textbf{n\\_non\\_stop\\_unique\\_tokens}     &      -0.2799  &        0.118     &    -2.374  &         0.018        &       -0.511    &       -0.049     \\\\\n",
       "\\textbf{num\\_hrefs}                       &       0.0042  &        0.001     &     8.441  &         0.000        &        0.003    &        0.005     \\\\\n",
       "\\textbf{num\\_self\\_hrefs}                 &      -0.0080  &        0.001     &    -6.104  &         0.000        &       -0.011    &       -0.005     \\\\\n",
       "\\textbf{num\\_imgs}                        &       0.0023  &        0.001     &     3.474  &         0.001        &        0.001    &        0.004     \\\\\n",
       "\\textbf{average\\_token\\_length}           &      -0.0955  &        0.018     &    -5.341  &         0.000        &       -0.131    &       -0.060     \\\\\n",
       "\\textbf{num\\_keywords}                    &       0.0124  &        0.003     &     4.458  &         0.000        &        0.007    &        0.018     \\\\\n",
       "\\textbf{data\\_channel\\_is\\_lifestyle}     &      -0.0830  &        0.025     &    -3.270  &         0.001        &       -0.133    &       -0.033     \\\\\n",
       "\\textbf{data\\_channel\\_is\\_entertainment} &      -0.1647  &        0.017     &    -9.646  &         0.000        &       -0.198    &       -0.131     \\\\\n",
       "\\textbf{data\\_channel\\_is\\_bus}           &      -0.1463  &        0.024     &    -6.080  &         0.000        &       -0.193    &       -0.099     \\\\\n",
       "\\textbf{data\\_channel\\_is\\_socmed}        &       0.1828  &        0.023     &     7.887  &         0.000        &        0.137    &        0.228     \\\\\n",
       "\\textbf{data\\_channel\\_is\\_tech}          &       0.1262  &        0.022     &     5.863  &         0.000        &        0.084    &        0.168     \\\\\n",
       "\\textbf{kw\\_min\\_min}                     &       0.0008  &     8.64e-05     &     9.334  &         0.000        &        0.001    &        0.001     \\\\\n",
       "\\textbf{kw\\_max\\_min}                     &    1.742e-05  &     3.81e-06     &     4.578  &         0.000        &     9.96e-06    &     2.49e-05     \\\\\n",
       "\\textbf{kw\\_avg\\_min}                     &      -0.0001  &     2.34e-05     &    -5.498  &         0.000        &       -0.000    &    -8.28e-05     \\\\\n",
       "\\textbf{kw\\_min\\_max}                     &   -3.716e-07  &     8.83e-08     &    -4.210  &         0.000        &    -5.45e-07    &    -1.99e-07     \\\\\n",
       "\\textbf{kw\\_avg\\_max}                     &   -2.527e-07  &     6.05e-08     &    -4.177  &         0.000        &    -3.71e-07    &    -1.34e-07     \\\\\n",
       "\\textbf{kw\\_min\\_avg}                     &   -5.138e-05  &      5.7e-06     &    -9.017  &         0.000        &    -6.25e-05    &    -4.02e-05     \\\\\n",
       "\\textbf{kw\\_max\\_avg}                     &   -4.254e-05  &     1.89e-06     &   -22.512  &         0.000        &    -4.62e-05    &    -3.88e-05     \\\\\n",
       "\\textbf{kw\\_avg\\_avg}                     &       0.0003  &     1.07e-05     &    31.601  &         0.000        &        0.000    &        0.000     \\\\\n",
       "\\textbf{self\\_reference\\_avg\\_sharess}    &    1.946e-06  &     1.85e-07     &    10.525  &         0.000        &     1.58e-06    &     2.31e-06     \\\\\n",
       "\\textbf{weekday\\_is\\_monday}              &      -0.2205  &        0.016     &   -13.573  &         0.000        &       -0.252    &       -0.189     \\\\\n",
       "\\textbf{weekday\\_is\\_tuesday}             &      -0.2875  &        0.016     &   -18.108  &         0.000        &       -0.319    &       -0.256     \\\\\n",
       "\\textbf{weekday\\_is\\_wednesday}           &      -0.2843  &        0.016     &   -17.902  &         0.000        &       -0.315    &       -0.253     \\\\\n",
       "\\textbf{weekday\\_is\\_thursday}            &      -0.2789  &        0.016     &   -17.503  &         0.000        &       -0.310    &       -0.248     \\\\\n",
       "\\textbf{weekday\\_is\\_friday}              &      -0.2152  &        0.017     &   -12.815  &         0.000        &       -0.248    &       -0.182     \\\\\n",
       "\\textbf{LDA\\_00}                          &       0.4729  &        0.036     &    13.254  &         0.000        &        0.403    &        0.543     \\\\\n",
       "\\textbf{LDA\\_01}                          &       0.1157  &        0.032     &     3.636  &         0.000        &        0.053    &        0.178     \\\\\n",
       "\\textbf{LDA\\_03}                          &       0.1409  &        0.028     &     5.116  &         0.000        &        0.087    &        0.195     \\\\\n",
       "\\textbf{LDA\\_04}                          &       0.2510  &        0.033     &     7.641  &         0.000        &        0.187    &        0.315     \\\\\n",
       "\\textbf{global\\_subjectivity}             &       0.3955  &        0.060     &     6.573  &         0.000        &        0.278    &        0.513     \\\\\n",
       "\\textbf{global\\_rate\\_positive\\_words}    &      -1.1234  &        0.365     &    -3.080  &         0.002        &       -1.838    &       -0.409     \\\\\n",
       "\\textbf{rate\\_positive\\_words}            &       0.2874  &        0.103     &     2.784  &         0.005        &        0.085    &        0.490     \\\\\n",
       "\\textbf{rate\\_negative\\_words}            &       0.2376  &        0.104     &     2.292  &         0.022        &        0.034    &        0.441     \\\\\n",
       "\\textbf{min\\_positive\\_polarity}          &      -0.3141  &        0.072     &    -4.379  &         0.000        &       -0.455    &       -0.173     \\\\\n",
       "\\textbf{avg\\_negative\\_polarity}          &      -0.1176  &        0.041     &    -2.833  &         0.005        &       -0.199    &       -0.036     \\\\\n",
       "\\textbf{title\\_subjectivity}              &       0.0712  &        0.016     &     4.441  &         0.000        &        0.040    &        0.103     \\\\\n",
       "\\textbf{title\\_sentiment\\_polarity}       &       0.0838  &        0.018     &     4.770  &         0.000        &        0.049    &        0.118     \\\\\n",
       "\\textbf{abs\\_title\\_subjectivity}         &       0.1384  &        0.027     &     5.043  &         0.000        &        0.085    &        0.192     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 7285.525 & \\textbf{  Durbin-Watson:     } &     1.952  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000  & \\textbf{  Jarque-Bera (JB):  } & 20289.897  \\\\\n",
       "\\textbf{Skew:}          &   0.984  & \\textbf{  Prob(JB):          } &      0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &   5.900  & \\textbf{  Cond. No.          } &  2.46e+07  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 2.46e+07. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                 shares   R-squared:                       0.127\n",
       "Model:                            OLS   Adj. R-squared:                  0.126\n",
       "Method:                 Least Squares   F-statistic:                     136.7\n",
       "Date:                Thu, 05 Dec 2024   Prob (F-statistic):               0.00\n",
       "Time:                        21:58:13   Log-Likelihood:                -50713.\n",
       "No. Observations:               39644   AIC:                         1.015e+05\n",
       "Df Residuals:                   39601   BIC:                         1.019e+05\n",
       "Df Model:                          42                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=================================================================================================\n",
       "                                    coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------------------------\n",
       "const                             6.5863      0.054    122.400      0.000       6.481       6.692\n",
       "timedelta                      5.821e-05   2.87e-05      2.031      0.042    2.04e-06       0.000\n",
       "n_tokens_title                    0.0081      0.002      3.657      0.000       0.004       0.012\n",
       "n_tokens_content               5.194e-05   1.26e-05      4.132      0.000    2.73e-05    7.66e-05\n",
       "n_unique_tokens                   0.2624      0.109      2.399      0.016       0.048       0.477\n",
       "n_non_stop_unique_tokens         -0.2799      0.118     -2.374      0.018      -0.511      -0.049\n",
       "num_hrefs                         0.0042      0.001      8.441      0.000       0.003       0.005\n",
       "num_self_hrefs                   -0.0080      0.001     -6.104      0.000      -0.011      -0.005\n",
       "num_imgs                          0.0023      0.001      3.474      0.001       0.001       0.004\n",
       "average_token_length             -0.0955      0.018     -5.341      0.000      -0.131      -0.060\n",
       "num_keywords                      0.0124      0.003      4.458      0.000       0.007       0.018\n",
       "data_channel_is_lifestyle        -0.0830      0.025     -3.270      0.001      -0.133      -0.033\n",
       "data_channel_is_entertainment    -0.1647      0.017     -9.646      0.000      -0.198      -0.131\n",
       "data_channel_is_bus              -0.1463      0.024     -6.080      0.000      -0.193      -0.099\n",
       "data_channel_is_socmed            0.1828      0.023      7.887      0.000       0.137       0.228\n",
       "data_channel_is_tech              0.1262      0.022      5.863      0.000       0.084       0.168\n",
       "kw_min_min                        0.0008   8.64e-05      9.334      0.000       0.001       0.001\n",
       "kw_max_min                     1.742e-05   3.81e-06      4.578      0.000    9.96e-06    2.49e-05\n",
       "kw_avg_min                       -0.0001   2.34e-05     -5.498      0.000      -0.000   -8.28e-05\n",
       "kw_min_max                    -3.716e-07   8.83e-08     -4.210      0.000   -5.45e-07   -1.99e-07\n",
       "kw_avg_max                    -2.527e-07   6.05e-08     -4.177      0.000   -3.71e-07   -1.34e-07\n",
       "kw_min_avg                    -5.138e-05    5.7e-06     -9.017      0.000   -6.25e-05   -4.02e-05\n",
       "kw_max_avg                    -4.254e-05   1.89e-06    -22.512      0.000   -4.62e-05   -3.88e-05\n",
       "kw_avg_avg                        0.0003   1.07e-05     31.601      0.000       0.000       0.000\n",
       "self_reference_avg_sharess     1.946e-06   1.85e-07     10.525      0.000    1.58e-06    2.31e-06\n",
       "weekday_is_monday                -0.2205      0.016    -13.573      0.000      -0.252      -0.189\n",
       "weekday_is_tuesday               -0.2875      0.016    -18.108      0.000      -0.319      -0.256\n",
       "weekday_is_wednesday             -0.2843      0.016    -17.902      0.000      -0.315      -0.253\n",
       "weekday_is_thursday              -0.2789      0.016    -17.503      0.000      -0.310      -0.248\n",
       "weekday_is_friday                -0.2152      0.017    -12.815      0.000      -0.248      -0.182\n",
       "LDA_00                            0.4729      0.036     13.254      0.000       0.403       0.543\n",
       "LDA_01                            0.1157      0.032      3.636      0.000       0.053       0.178\n",
       "LDA_03                            0.1409      0.028      5.116      0.000       0.087       0.195\n",
       "LDA_04                            0.2510      0.033      7.641      0.000       0.187       0.315\n",
       "global_subjectivity               0.3955      0.060      6.573      0.000       0.278       0.513\n",
       "global_rate_positive_words       -1.1234      0.365     -3.080      0.002      -1.838      -0.409\n",
       "rate_positive_words               0.2874      0.103      2.784      0.005       0.085       0.490\n",
       "rate_negative_words               0.2376      0.104      2.292      0.022       0.034       0.441\n",
       "min_positive_polarity            -0.3141      0.072     -4.379      0.000      -0.455      -0.173\n",
       "avg_negative_polarity            -0.1176      0.041     -2.833      0.005      -0.199      -0.036\n",
       "title_subjectivity                0.0712      0.016      4.441      0.000       0.040       0.103\n",
       "title_sentiment_polarity          0.0838      0.018      4.770      0.000       0.049       0.118\n",
       "abs_title_subjectivity            0.1384      0.027      5.043      0.000       0.085       0.192\n",
       "==============================================================================\n",
       "Omnibus:                     7285.525   Durbin-Watson:                   1.952\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            20289.897\n",
       "Skew:                           0.984   Prob(JB):                         0.00\n",
       "Kurtosis:                       5.900   Cond. No.                     2.46e+07\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 2.46e+07. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned_model, tuned_X = remove_insignificant_features(linear_model, X, y)\n",
    "tuned_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The five most significant features are:\n",
      "                Feature        P-value\n",
      "1            kw_avg_avg  1.788142e-216\n",
      "2            kw_max_avg  1.595246e-111\n",
      "3    weekday_is_tuesday   5.428202e-73\n",
      "4  weekday_is_wednesday   2.182979e-71\n",
      "5   weekday_is_thursday   2.468833e-68\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>P-value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>const</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kw_avg_avg</td>\n",
       "      <td>1.788142e-216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kw_max_avg</td>\n",
       "      <td>1.595246e-111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>weekday_is_tuesday</td>\n",
       "      <td>5.428202e-73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>weekday_is_wednesday</td>\n",
       "      <td>2.182979e-71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>weekday_is_thursday</td>\n",
       "      <td>2.468833e-68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>weekday_is_monday</td>\n",
       "      <td>7.216608e-42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LDA_00</td>\n",
       "      <td>5.191217e-40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>weekday_is_friday</td>\n",
       "      <td>1.598841e-37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>self_reference_avg_sharess</td>\n",
       "      <td>7.185713e-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>data_channel_is_entertainment</td>\n",
       "      <td>5.428686e-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>kw_min_min</td>\n",
       "      <td>1.068321e-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>kw_min_avg</td>\n",
       "      <td>2.025765e-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>num_hrefs</td>\n",
       "      <td>3.265475e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>data_channel_is_socmed</td>\n",
       "      <td>3.176659e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LDA_04</td>\n",
       "      <td>2.205299e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>global_subjectivity</td>\n",
       "      <td>4.999586e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>num_self_hrefs</td>\n",
       "      <td>1.041634e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>data_channel_is_bus</td>\n",
       "      <td>1.209078e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>data_channel_is_tech</td>\n",
       "      <td>4.582023e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>kw_avg_min</td>\n",
       "      <td>3.873565e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>average_token_length</td>\n",
       "      <td>9.303982e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>LDA_03</td>\n",
       "      <td>3.134628e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>abs_title_subjectivity</td>\n",
       "      <td>4.606186e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>title_sentiment_polarity</td>\n",
       "      <td>1.848110e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>kw_max_min</td>\n",
       "      <td>4.719233e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>num_keywords</td>\n",
       "      <td>8.287213e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>title_subjectivity</td>\n",
       "      <td>8.971576e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>min_positive_polarity</td>\n",
       "      <td>1.196247e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>kw_min_max</td>\n",
       "      <td>2.557480e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>kw_avg_max</td>\n",
       "      <td>2.957975e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>n_tokens_content</td>\n",
       "      <td>3.609320e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>n_tokens_title</td>\n",
       "      <td>2.555542e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>LDA_01</td>\n",
       "      <td>2.772107e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>num_imgs</td>\n",
       "      <td>5.129700e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>data_channel_is_lifestyle</td>\n",
       "      <td>1.074793e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>global_rate_positive_words</td>\n",
       "      <td>2.068248e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>avg_negative_polarity</td>\n",
       "      <td>4.610109e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>rate_positive_words</td>\n",
       "      <td>5.373599e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>n_unique_tokens</td>\n",
       "      <td>1.643598e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>n_non_stop_unique_tokens</td>\n",
       "      <td>1.761456e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>rate_negative_words</td>\n",
       "      <td>2.190463e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>timedelta</td>\n",
       "      <td>4.224388e-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Feature        P-value\n",
       "0                           const   0.000000e+00\n",
       "1                      kw_avg_avg  1.788142e-216\n",
       "2                      kw_max_avg  1.595246e-111\n",
       "3              weekday_is_tuesday   5.428202e-73\n",
       "4            weekday_is_wednesday   2.182979e-71\n",
       "5             weekday_is_thursday   2.468833e-68\n",
       "6               weekday_is_monday   7.216608e-42\n",
       "7                          LDA_00   5.191217e-40\n",
       "8               weekday_is_friday   1.598841e-37\n",
       "9      self_reference_avg_sharess   7.185713e-26\n",
       "10  data_channel_is_entertainment   5.428686e-22\n",
       "11                     kw_min_min   1.068321e-20\n",
       "12                     kw_min_avg   2.025765e-19\n",
       "13                      num_hrefs   3.265475e-17\n",
       "14         data_channel_is_socmed   3.176659e-15\n",
       "15                         LDA_04   2.205299e-14\n",
       "16            global_subjectivity   4.999586e-11\n",
       "17                 num_self_hrefs   1.041634e-09\n",
       "18            data_channel_is_bus   1.209078e-09\n",
       "19           data_channel_is_tech   4.582023e-09\n",
       "20                     kw_avg_min   3.873565e-08\n",
       "21           average_token_length   9.303982e-08\n",
       "22                         LDA_03   3.134628e-07\n",
       "23         abs_title_subjectivity   4.606186e-07\n",
       "24       title_sentiment_polarity   1.848110e-06\n",
       "25                     kw_max_min   4.719233e-06\n",
       "26                   num_keywords   8.287213e-06\n",
       "27             title_subjectivity   8.971576e-06\n",
       "28          min_positive_polarity   1.196247e-05\n",
       "29                     kw_min_max   2.557480e-05\n",
       "30                     kw_avg_max   2.957975e-05\n",
       "31               n_tokens_content   3.609320e-05\n",
       "32                 n_tokens_title   2.555542e-04\n",
       "33                         LDA_01   2.772107e-04\n",
       "34                       num_imgs   5.129700e-04\n",
       "35      data_channel_is_lifestyle   1.074793e-03\n",
       "36     global_rate_positive_words   2.068248e-03\n",
       "37          avg_negative_polarity   4.610109e-03\n",
       "38            rate_positive_words   5.373599e-03\n",
       "39                n_unique_tokens   1.643598e-02\n",
       "40       n_non_stop_unique_tokens   1.761456e-02\n",
       "41            rate_negative_words   2.190463e-02\n",
       "42                      timedelta   4.224388e-02"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_features = sorted(zip(tuned_model.pvalues.index, tuned_model.pvalues), key=lambda x: x[1])\n",
    "sorted_features = pd.DataFrame(sorted_features, columns=[\"Feature\", \"P-value\"])\n",
    "print(f\"The five most significant features are:\\n{sorted_features.drop(0).head()}\")\n",
    "sorted_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Build a regression tree to identify important predictors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Select several significant features from steps 2 and 3. Create visualizations or\n",
    "# tables to explore the relationships between these features and the target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Write an EDA section in your technical report. Report the results of the ini-\n",
    "tial models and include figures or tables that show the target variable and its\n",
    "relationship with potentially significant predictors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Use appropriate methods to remove insignificant variables from the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression Modeling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Split the data into training and testing sets. Use the training set for model fitting\n",
    "# and the testing set to check for overfitting and predictive performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Explore transformations of the target and other variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Explore higher-order terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"4. Reduce the model using the following methods:\n",
    "• Stepwise model evaluation methods to remove insignificant variables.\n",
    "• LASSO regression to fit the full model and remove insignificant variables.\n",
    "Tune the model to find the best a.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Write a section in your technical report that reports the out-of-sample perfor-\n",
    "mance of the models. Discuss the most significant predictors and evaluate the\n",
    "model?s usefulness for predicting future shares."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Tree Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Use the same training and testing sets as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Use cost-complexity pruning and cross-validation to find a model that fits well\n",
    "# on out-of-sample data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Fit a random forest regression model, using cost-complexity pruning for the in-\n",
    "# dividual trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Write a section in your technical report that reports the out-of-sample perfor-\n",
    "# mance of the models. Discuss the model's usefulness for predicting future shares."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare each model’s predictive accuracy on the test set. Choose the\n",
    "best-performing model as the final predictive model. Write a concluding section in\n",
    "your technical report that addresses Mashable?s business concerns and presents your\n",
    "final model along with your confidence in its predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
